{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import argparse\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose from the following:\n",
      "1 - Image Colorization\n",
      "2 - Video Colorization\n"
     ]
    }
   ],
   "source": [
    "print(\"Choose from the following:\")\n",
    "print(\"1 - Image Colorization\")\n",
    "print(\"2 - Video Colorization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imagecolorize():\n",
    "    print(\"Enter the image name to be processed along with extension\")\n",
    "    s=input()\n",
    "# Read the input image\n",
    "    frame = cv.imread(s)\n",
    "\n",
    "# Specify the paths for the 2 model files\n",
    "    protoFile = \"colorization_deploy_v2.prototxt\"\n",
    "    weightsFile = \"colorization_release_v2.caffemodel\"\n",
    "#weightsFile = \"./models/colorization_release_v2_norebal.caffemodel\"\n",
    "\n",
    "# Load the cluster centers\n",
    "    pts_in_hull = np.load('./pts_in_hull.npy')\n",
    "\n",
    "# Read the network into Memory\n",
    "    net = cv.dnn.readNetFromCaffe(protoFile, weightsFile)\n",
    "\n",
    "# populate cluster centers as 1x1 convolution kernel\n",
    "    pts_in_hull = pts_in_hull.transpose().reshape(2, 313, 1, 1)\n",
    "    net.getLayer(net.getLayerId('class8_ab')).blobs = [pts_in_hull.astype(np.float32)]\n",
    "    net.getLayer(net.getLayerId('conv8_313_rh')).blobs = [np.full([1, 313], 2.606, np.float32)]\n",
    "\n",
    "#from opencv sample\n",
    "    W_in = 224\n",
    "    H_in = 224\n",
    "    \n",
    "    img_rgb = (frame[:,:,[2, 1, 0]] * 1.0 / 255).astype(np.float32)\n",
    "    img_lab = cv.cvtColor(img_rgb, cv.COLOR_RGB2Lab)\n",
    "    img_l = img_lab[:,:,0] # pull out L channel\n",
    "\n",
    "# resize lightness channel to network input size\n",
    "    img_l_rs = cv.resize(img_l, (W_in, H_in)) #\n",
    "    img_l_rs -= 50 # subtract 50 for mean-centering\n",
    "\n",
    "    net.setInput(cv.dnn.blobFromImage(img_l_rs))\n",
    "    ab_dec = net.forward()[0,:,:,:].transpose((1,2,0)) # this is our result\n",
    "\n",
    "    (H_orig,W_orig) = img_rgb.shape[:2] # original image size\n",
    "    ab_dec_us = cv.resize(ab_dec, (W_orig, H_orig))\n",
    "    img_lab_out = np.concatenate((img_l[:,:,np.newaxis],ab_dec_us),axis=2) # concatenate with original image L\n",
    "    img_bgr_out = np.clip(cv.cvtColor(img_lab_out, cv.COLOR_Lab2BGR), 0, 1)\n",
    "\n",
    "    outputFile = s[:-4]+\"colorized.jpg\";\n",
    "    cv.imwrite(outputFile, (img_bgr_out*255).astype(np.uint8))\n",
    "    print('Colorized image saved as '+outputFile)\n",
    "    print('Done !!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def videocolorize():\n",
    "    print(\"Enter video file to be processed along with extension\")\n",
    "    s=input()\n",
    "# Read the input video\n",
    "    cap = cv.VideoCapture(s)\n",
    "    hasFrame, frame = cap.read()\n",
    "\n",
    "    outputFile = s[:-4]+'_colorized.avi'\n",
    "    vid_writer = cv.VideoWriter(outputFile, cv.VideoWriter_fourcc('M','J','P','G'), 60, (frame.shape[1],frame.shape[0]))\n",
    "\n",
    "# Specify the paths for the 2 model files\n",
    "    protoFile = \"colorization_deploy_v2.prototxt\"\n",
    "    weightsFile = \"colorization_release_v2.caffemodel\"\n",
    "#weightsFile = \"./models/colorization_release_v2_norebal.caffemodel\"\n",
    "\n",
    "# Load the cluster centers\n",
    "    pts_in_hull = np.load('./pts_in_hull.npy')\n",
    "\n",
    "# Read the network into Memory\n",
    "    net = cv.dnn.readNetFromCaffe(protoFile, weightsFile)\n",
    "\n",
    "# populate cluster centers as 1x1 convolution kernel\n",
    "    pts_in_hull = pts_in_hull.transpose().reshape(2, 313, 1, 1)\n",
    "    net.getLayer(net.getLayerId('class8_ab')).blobs = [pts_in_hull.astype(np.float32)]\n",
    "    net.getLayer(net.getLayerId('conv8_313_rh')).blobs = [np.full([1, 313], 2.606, np.float32)]\n",
    "\n",
    "#from opencv sample\n",
    "    W_in = 224\n",
    "    H_in = 224\n",
    "\n",
    "    while cv.waitKey(1):\n",
    "\n",
    "        hasFrame, frame = cap.read()\n",
    "        frameCopy = np.copy(frame)\n",
    "        if not hasFrame:\n",
    "            break\n",
    "\n",
    "        img_rgb = (frame[:,:,[2, 1, 0]] * 1.0 / 255).astype(np.float32)\n",
    "        img_lab = cv.cvtColor(img_rgb, cv.COLOR_RGB2Lab)\n",
    "        img_l = img_lab[:,:,0] # pull out L channel\n",
    "\n",
    "    # resize lightness channel to network input size\n",
    "        img_l_rs = cv.resize(img_l, (W_in, H_in))\n",
    "        img_l_rs -= 50 # subtract 50 for mean-centering\n",
    "\n",
    "        net.setInput(cv.dnn.blobFromImage(img_l_rs))\n",
    "        ab_dec = net.forward()[0,:,:,:].transpose((1,2,0)) # this is our result\n",
    "\n",
    "        (H_orig,W_orig) = img_rgb.shape[:2] # original image size\n",
    "        ab_dec_us = cv.resize(ab_dec, (W_orig, H_orig))\n",
    "        img_lab_out = np.concatenate((img_l[:,:,np.newaxis],ab_dec_us),axis=2) # concatenate with original L channel\n",
    "        img_bgr_out = np.clip(cv.cvtColor(img_lab_out, cv.COLOR_Lab2BGR), 0, 1)\n",
    "\n",
    "        vid_writer.write((img_bgr_out*255).astype(np.uint8))\n",
    "\n",
    "    vid_writer.release()\n",
    "\n",
    "    print('Colorized video saved as '+outputFile)\n",
    "    print('Done !!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Enter the image name to be processed along with extension\n",
      "pic1.jpeg\n",
      "Colorized image saved as pic1.colorized.jpg\n",
      "Done !!!\n"
     ]
    }
   ],
   "source": [
    "n=int(input())\n",
    "if(n==1):\n",
    "    imagecolorize()\n",
    "elif(n==2):\n",
    "    videocolorize()\n",
    "else:\n",
    "    print(\"Invalid input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
